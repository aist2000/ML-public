{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObuCW/8nBc0kv4wDR1x75q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aist2000/ML-public/blob/master/el2/TCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TCN method"
      ],
      "metadata": {
        "id": "fZPXmERnW7U5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1fy6WavzW0lY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Dropout, Activation, TimeDistributed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def create_dataset(dataset, window_size=1, stride=1):\n",
        "    \"\"\"\n",
        "    Creates a dataset of sliding windows.\n",
        "\n",
        "    Args:\n",
        "      dataset: The input dataset as a NumPy array.\n",
        "      window_size: The size of the sliding window.\n",
        "      stride: The stride for the sliding window.\n",
        "\n",
        "    Returns:\n",
        "      A NumPy array of windows.\n",
        "    \"\"\"\n",
        "    X = list()\n",
        "    for i in range(window_size, len(dataset) - window_size + 1, stride):\n",
        "        X.append(dataset[i-window_size:i, 1:])  # Exclude time column\n",
        "    return np.array(X)\n",
        "\n",
        "def train_model(X_train):\n",
        "    \"\"\"\n",
        "    Trains a TCN autoencoder model for anomaly detection.\n",
        "\n",
        "    Args:\n",
        "      X_train: The training input data.\n",
        "\n",
        "    Returns:\n",
        "      A trained TCN autoencoder model.\n",
        "    \"\"\"\n",
        "    num_features = X_train.shape[2]\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(window_size, num_features), padding='same', dilation_rate=1))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', dilation_rate=2))\n",
        "    model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same', dilation_rate=4))\n",
        "    # Add more Conv1D layers with increasing dilation rates as needed\n",
        "\n",
        "    # Decoder (upsampling and reconstruction)\n",
        "    model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same', dilation_rate=4))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', dilation_rate=2))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', dilation_rate=1))\n",
        "    model.add(TimeDistributed(Dense(num_features)))  # Reconstruct the input\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    model.fit(X_train, X_train, epochs=100, batch_size=32, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
        "    return model\n",
        "\n",
        "def predict_anomalies(model, X_test, threshold=0.1, stride=1):\n",
        "    \"\"\"\n",
        "    Predicts anomaly windows and observations based on the trained model and a threshold.\n",
        "\n",
        "    Args:\n",
        "      model: The trained TCN autoencoder model.\n",
        "      X_test: The test input data.\n",
        "      threshold: The threshold for anomaly detection.\n",
        "      stride: The stride used for creating the sliding windows.\n",
        "\n",
        "    Returns:\n",
        "      A tuple containing:\n",
        "        - anomaly_windows: A list of indices for windows containing anomalies.\n",
        "        - anomaly_observations: A list of indices for observations considered anomalous.\n",
        "    \"\"\"\n",
        "    predictions = model.predict(X_test)\n",
        "    mse = np.mean(np.square(predictions - X_test), axis=2)  # Calculate MSE for each time step\n",
        "    threshold = np.percentile(mse, 95)  # Example threshold (95th percentile)\n",
        "\n",
        "    anomaly_windows = np.where(np.any(mse > threshold, axis=1))[0]  # Identify anomaly windows\n",
        "    anomaly_observations = list()\n",
        "    for window_index in anomaly_windows:\n",
        "        window = mse[window_index]\n",
        "        anomaly_indices = np.where(window > threshold)[0]  # Find anomalies within the window\n",
        "        # Adjust indices to correspond to original dataset\n",
        "        anomaly_observations.extend(window_index * stride + anomaly_indices)\n",
        "\n",
        "    return anomaly_windows, anomaly_observations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "data = np.array([\n",
        "   [100,0, 0], [101,0, 0],[102,0, 1],[103,0, 1],[104,0, 1],[105,1, 1],[106,0, 1],[107,0, 1],[108,0, 1],[109,1, 1],[110,0, 1]\n",
        "              ,[111,0, 0], [112,0, 0],[113,0, 1],[114,0, 1],[115,0, 1],[116,1, 1],[117,0, 1],[118,0, 1],[119,0, 1],[120,1, 1]\n",
        "              ,[121,0, 0], [122,0, 0],[123,0, 1],[124,0, 1],[125,0, 1],[126,1, 1],[127,0, 1],[128,0, 1],[129,0, 1],[130,1, 1]\n",
        "  ])\n",
        "url=\"https://raw.githubusercontent.com/aist2000/ML-public/master/dataset.csv\"\n",
        "#url=\"dataset.csv\"\n",
        "df = pd.read_csv(url, skiprows=2, header=None)\n",
        "display(df.head())\n",
        "display(df.describe())"
      ],
      "metadata": {
        "id": "VNGV0XMgOmdT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "# Assuming your data is in a NumPy array called 'data' with shape (num_samples, 31)\n",
        "# where the first column is time and the rest are the 30 features\n",
        "\n",
        "\n",
        "# 1. Data Preprocessing\n",
        "scaler = StandardScaler()\n",
        "data[:, 1:] = scaler.fit_transform(data[:, 1:])  # Standardize features\n",
        "window_size = 4 #10000  # Set window size to 10,000\n",
        "stride = 2      # 1000  # Adjust stride as needed\n",
        "X = create_dataset(data, window_size, stride)\n",
        "\n",
        "# 2. Train-Test Split (adjust split ratio as needed)\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "\n",
        "# 3. Model Training\n",
        "model = train_model(X_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7C7SBDKOiN1",
        "outputId": "a577b7e0-4622-4018-9a1f-8f72450d372b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.7107 - val_loss: 0.4943\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.7033 - val_loss: 0.4905\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6960 - val_loss: 0.4867\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6884 - val_loss: 0.4826\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6803 - val_loss: 0.4782\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6712 - val_loss: 0.4734\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.6612 - val_loss: 0.4685\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.6502 - val_loss: 0.4634\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.6382 - val_loss: 0.4583\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.6254 - val_loss: 0.4532\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.6116 - val_loss: 0.4483\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.5967 - val_loss: 0.4436\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5809 - val_loss: 0.4393\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5644 - val_loss: 0.4359\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5475 - val_loss: 0.4339\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.5308 - val_loss: 0.4333\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5148 - val_loss: 0.4344\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.4998 - val_loss: 0.4375\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.4863 - val_loss: 0.4422\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4743 - val_loss: 0.4471\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4631 - val_loss: 0.4509\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4520 - val_loss: 0.4522\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.4394 - val_loss: 0.4503\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4247 - val_loss: 0.4452\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.4079 - val_loss: 0.4366\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3894 - val_loss: 0.4250\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.3696 - val_loss: 0.4110\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.3488 - val_loss: 0.3963\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3277 - val_loss: 0.3810\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3070 - val_loss: 0.3656\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.2866 - val_loss: 0.3498\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2660 - val_loss: 0.3336\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2458 - val_loss: 0.3171\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.2260 - val_loss: 0.3005\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2066 - val_loss: 0.2834\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1879 - val_loss: 0.2652\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1702 - val_loss: 0.2465\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1541 - val_loss: 0.2270\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1394 - val_loss: 0.2068\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.1259 - val_loss: 0.1868\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.1135 - val_loss: 0.1675\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1024 - val_loss: 0.1496\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0924 - val_loss: 0.1337\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0838 - val_loss: 0.1199\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0767 - val_loss: 0.1081\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0707 - val_loss: 0.0989\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0658 - val_loss: 0.0924\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0615 - val_loss: 0.0881\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0576 - val_loss: 0.0860\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0538 - val_loss: 0.0855\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0499 - val_loss: 0.0859\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0456 - val_loss: 0.0872\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0414 - val_loss: 0.0890\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0376 - val_loss: 0.0914\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0342 - val_loss: 0.0942\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0314 - val_loss: 0.0974\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0290 - val_loss: 0.1008\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0268 - val_loss: 0.1042\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0248 - val_loss: 0.1074\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0231 - val_loss: 0.1102\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
            "Anomaly Windows: [0]\n",
            "Anomaly Observations: [3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeEwcx74P1WW",
        "outputId": "31045ef1-eace-4702-ae74-486abb4ab045"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0  0]\n",
            "  [ 0  0]\n",
            "  [ 2  0]\n",
            "  [ 0 -2]]\n",
            "\n",
            " [[ 2  0]\n",
            "  [ 0 -2]\n",
            "  [ 0 -2]\n",
            "  [ 0  0]]\n",
            "\n",
            " [[ 0 -2]\n",
            "  [ 0  0]\n",
            "  [ 0  0]\n",
            "  [ 0  0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Anomaly Prediction\n",
        "threshold = 0.1  # Adjust threshold as needed\n",
        "\n",
        "anomaly_windows, anomaly_observations = predict_anomalies(model, X_test, threshold, stride)\n",
        "\n",
        "# Print the results\n",
        "print(\"Anomaly Windows:\", anomaly_windows)\n",
        "print(\"Anomaly Observations:\", anomaly_observations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuQrRWCvO5Z-",
        "outputId": "bcdfcd91-1bba-483d-ab73-177dd8badbd5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Anomaly Windows: [0]\n",
            "Anomaly Observations: [3]\n"
          ]
        }
      ]
    }
  ]
}